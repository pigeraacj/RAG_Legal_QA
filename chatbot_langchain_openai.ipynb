{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "[# Simple Chatbot using LangChain and OpenAI](https://)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "-MRhelrPEksv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install the necessary packages\n",
        "!pip install langchain -qU\n",
        "!pip install langchain-openai -qU"
      ],
      "metadata": {
        "id": "1ww-6rL2E7No"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "import os\n",
        "from google.colab import userdata"
      ],
      "metadata": {
        "id": "xI1gzr4WHaYY"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Initialize OpenAI LLM"
      ],
      "metadata": {
        "id": "sG3tHac5H6Z_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "# Set OpenAI API key\n",
        "os.environ['OPENAI_API_KEY'] = userdata.get('OPENAI_API_KEY')\n",
        "\n",
        "# Initialize the ChatOpenAI model\n",
        "llm = ChatOpenAI(\n",
        "    model=\"gpt-3.5-turbo\",\n",
        "    temperature=0\n",
        ")"
      ],
      "metadata": {
        "id": "Em6EyJxkIFrw"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Initialize Prompt Template"
      ],
      "metadata": {
        "id": "PnZKB6amKxkY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "\n",
        "# Create a prompt template\n",
        "prompt = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        (\"system\",\"You are an intelligent chatbot. Answer the following question.\"),\n",
        "        (\"user\", \"{question}\")\n",
        "    ]\n",
        ")"
      ],
      "metadata": {
        "id": "PS6383QUK_ER"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Initialize Output Parser"
      ],
      "metadata": {
        "id": "ZLJFkkoDLnyP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.output_parsers import StrOutputParser\n",
        "\n",
        "# Initialize the string output parser\n",
        "parser = StrOutputParser()"
      ],
      "metadata": {
        "id": "yI4K1kqeLurA"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Chain the prompt, LLM, and output parser\n",
        "chain = prompt | llm | parser"
      ],
      "metadata": {
        "id": "2w3xWQWFLxa3"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "question = \"My name is codeprolk\"\n",
        "\n",
        "response = chain.invoke({\"question\": question})\n",
        "\n",
        "print(response)"
      ],
      "metadata": {
        "id": "07q3Vd7NMDQY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Initialize Prompt Template for Dynamic Interaction"
      ],
      "metadata": {
        "id": "_DKfMZtXMhRX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.prompts import MessagesPlaceholder\n",
        "from langchain_core.messages import HumanMessage, AIMessage, SystemMessage\n",
        "\n",
        "# Create a prompt template using MessagesPlaceholder for the question\n",
        "prompt = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        SystemMessage(content=\"You are an intelligent chatbot. Answer the following question.\"),\n",
        "        MessagesPlaceholder(variable_name=\"question\")\n",
        "    ]\n",
        ")\n",
        "\n",
        "# Chain the prompt, LLM, and output parser\n",
        "chain = prompt | llm | parser"
      ],
      "metadata": {
        "id": "E3OaK8CVMn53"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "question = \"My name is codeprolk\"\n",
        "\n",
        "response = chain.invoke({\"question\": [HumanMessage(content=question)]})\n",
        "\n",
        "print(response)"
      ],
      "metadata": {
        "id": "Z6jWw3mdMphP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "question = \"Who am I\"\n",
        "\n",
        "response = chain.invoke({\"question\": [HumanMessage(content=question)]})\n",
        "\n",
        "print(response)"
      ],
      "metadata": {
        "id": "z8Lda9JWMr8x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Initialize Prompt Template with Predefined Conversation History"
      ],
      "metadata": {
        "id": "7BX6R_wEM1-H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a prompt template with a predefined conversation history and a new question placeholder\n",
        "prompt = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        SystemMessage(content=\"You are an intelligent chatbot. Answer the following question.\"),\n",
        "        HumanMessage(content=\"My name is codeprolk\"),\n",
        "        AIMessage(content=\"Nice to meet you, codeprolk! How can I assist you today?\"),\n",
        "        MessagesPlaceholder(variable_name=\"question\")\n",
        "    ]\n",
        ")\n",
        "\n",
        "# Chain the prompt, LLM, and output parser\n",
        "chain = prompt | llm | parser"
      ],
      "metadata": {
        "id": "P5JdhhmLM54v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "question = \"Who am I\"\n",
        "\n",
        "response = chain.invoke({\"question\": [HumanMessage(content=question)]})\n",
        "\n",
        "print(response)"
      ],
      "metadata": {
        "id": "j0MVSsXrNaYA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Initialize Prompt Template to Handle Dynamic Conversation History"
      ],
      "metadata": {
        "id": "JTVehL8TN28Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a prompt template with a dynamic conversation history and a new question placeholder\n",
        "prompt = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        SystemMessage(content=\"You are an intelligent chatbot. Answer the following question.\"),\n",
        "        MessagesPlaceholder(variable_name=\"history\"),\n",
        "        MessagesPlaceholder(variable_name=\"question\")\n",
        "    ]\n",
        ")\n",
        "\n",
        "# Chain the prompt, LLM, and output parser\n",
        "chain = prompt | llm | parser"
      ],
      "metadata": {
        "id": "7gPIO-wCN6bY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the conversation history\n",
        "history = [\n",
        "    HumanMessage(content=\"My name is codeprolk\"),\n",
        "    AIMessage(content=\"Nice to meet you, codeprolk! How can I assist you today?\"),\n",
        "    HumanMessage(content=\"what is 2 + 2\"),\n",
        "    AIMessage(content=\"4\")\n",
        "]"
      ],
      "metadata": {
        "id": "LKzeWeL2N-RI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "question = \"Who am I\"\n",
        "\n",
        "response = chain.invoke({\"history\": history, \"question\": [HumanMessage(content=question)]})\n",
        "\n",
        "print(response)"
      ],
      "metadata": {
        "id": "liq_i8YvOANg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Update and Display Conversation History"
      ],
      "metadata": {
        "id": "IMZz23h4ODSH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "history"
      ],
      "metadata": {
        "id": "wE_FnJ8YOGQQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Extend the history with the latest question and response\n",
        "history.extend([HumanMessage(content=question), AIMessage(content=response)])"
      ],
      "metadata": {
        "id": "aCU1aHGST5iA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history"
      ],
      "metadata": {
        "id": "LWrXGTOUT8Vg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "question = \"what's my last question?\"\n",
        "\n",
        "response = chain.invoke({\"history\": history, \"question\": [HumanMessage(content=question)]})\n",
        "\n",
        "history.extend([HumanMessage(content=question), AIMessage(content=response)])\n",
        "\n",
        "print(response)"
      ],
      "metadata": {
        "id": "Qm9n7XDMT-m4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history"
      ],
      "metadata": {
        "id": "eYTvlHivUB5A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Display the last four interactions in the conversation history\n",
        "history[-4:]"
      ],
      "metadata": {
        "id": "ApbsW60mUDvo"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}